{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nJ2X_5sG7Qox",
    "outputId": "e2324396-4098-4757-986b-20c420bec267"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch>=1.8.1 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (2.5.1)\n",
      "Requirement already satisfied: torchvision>=0.13.0 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (0.20.1)\n",
      "Requirement already satisfied: pytorch-lightning>=2.0 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (2.4.0)\n",
      "Requirement already satisfied: lightning-bolts in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (0.5.0)\n",
      "Requirement already satisfied: torchmetrics>=1.0 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (1.6.0)\n",
      "Requirement already satisfied: timm in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (1.0.11)\n",
      "Requirement already satisfied: matplotlib in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (3.9.2)\n",
      "Requirement already satisfied: seaborn in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from -r requirements.txt (line 8)) (0.13.2)\n",
      "Requirement already satisfied: tqdm in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from -r requirements.txt (line 9)) (4.67.1)\n",
      "Requirement already satisfied: numpy in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from -r requirements.txt (line 10)) (2.1.3)\n",
      "Requirement already satisfied: wandb in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from -r requirements.txt (line 11)) (0.18.7)\n",
      "Requirement already satisfied: pre-commit in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from -r requirements.txt (line 12)) (4.0.1)\n",
      "Requirement already satisfied: captum in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from -r requirements.txt (line 13)) (0.7.0)\n",
      "Requirement already satisfied: filelock in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from torch>=1.8.1->-r requirements.txt (line 1)) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from torch>=1.8.1->-r requirements.txt (line 1)) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from torch>=1.8.1->-r requirements.txt (line 1)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from torch>=1.8.1->-r requirements.txt (line 1)) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from torch>=1.8.1->-r requirements.txt (line 1)) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from torch>=1.8.1->-r requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from torch>=1.8.1->-r requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from torch>=1.8.1->-r requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from torch>=1.8.1->-r requirements.txt (line 1)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from torch>=1.8.1->-r requirements.txt (line 1)) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from torch>=1.8.1->-r requirements.txt (line 1)) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from torch>=1.8.1->-r requirements.txt (line 1)) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from torch>=1.8.1->-r requirements.txt (line 1)) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from torch>=1.8.1->-r requirements.txt (line 1)) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from torch>=1.8.1->-r requirements.txt (line 1)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from torch>=1.8.1->-r requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from torch>=1.8.1->-r requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from torch>=1.8.1->-r requirements.txt (line 1)) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from torch>=1.8.1->-r requirements.txt (line 1)) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from torch>=1.8.1->-r requirements.txt (line 1)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.8.1->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from torchvision>=0.13.0->-r requirements.txt (line 2)) (11.0.0)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from pytorch-lightning>=2.0->-r requirements.txt (line 3)) (6.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from pytorch-lightning>=2.0->-r requirements.txt (line 3)) (24.2)\n",
      "Requirement already satisfied: lightning-utilities>=0.10.0 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from pytorch-lightning>=2.0->-r requirements.txt (line 3)) (0.11.9)\n",
      "Requirement already satisfied: huggingface_hub in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from timm->-r requirements.txt (line 6)) (0.26.2)\n",
      "Requirement already satisfied: safetensors in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from timm->-r requirements.txt (line 6)) (0.4.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 7)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 7)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 7)) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 7)) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 7)) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 7)) (2.9.0.post0)\n",
      "Requirement already satisfied: pandas>=1.2 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from seaborn->-r requirements.txt (line 8)) (2.2.3)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from wandb->-r requirements.txt (line 11)) (8.1.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from wandb->-r requirements.txt (line 11)) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from wandb->-r requirements.txt (line 11)) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from wandb->-r requirements.txt (line 11)) (4.3.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from wandb->-r requirements.txt (line 11)) (5.28.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from wandb->-r requirements.txt (line 11)) (6.1.0)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from wandb->-r requirements.txt (line 11)) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from wandb->-r requirements.txt (line 11)) (2.19.0)\n",
      "Requirement already satisfied: setproctitle in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from wandb->-r requirements.txt (line 11)) (1.3.4)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from pre-commit->-r requirements.txt (line 12)) (3.4.0)\n",
      "Requirement already satisfied: identify>=1.0.0 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from pre-commit->-r requirements.txt (line 12)) (2.6.2)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from pre-commit->-r requirements.txt (line 12)) (1.9.1)\n",
      "Requirement already satisfied: virtualenv>=20.10.0 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from pre-commit->-r requirements.txt (line 12)) (20.27.1)\n",
      "Requirement already satisfied: six>=1.4.0 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from docker-pycreds>=0.4.0->wandb->-r requirements.txt (line 11)) (1.16.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=2.0->-r requirements.txt (line 3)) (3.11.7)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 11)) (4.0.11)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from pandas>=1.2->seaborn->-r requirements.txt (line 8)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from pandas>=1.2->seaborn->-r requirements.txt (line 8)) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 11)) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 11)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 11)) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 11)) (2024.8.30)\n",
      "Requirement already satisfied: distlib<1,>=0.3.7 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from virtualenv>=20.10.0->pre-commit->-r requirements.txt (line 12)) (0.3.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from jinja2->torch>=1.8.1->-r requirements.txt (line 1)) (3.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0->-r requirements.txt (line 3)) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0->-r requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0->-r requirements.txt (line 3)) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0->-r requirements.txt (line 3)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0->-r requirements.txt (line 3)) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0->-r requirements.txt (line 3)) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0->-r requirements.txt (line 3)) (1.18.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/leo/uni/ml_for_NLP/practical/ml-venv/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 11)) (5.0.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "kp_z2uj77UXD",
    "outputId": "fa1d5148-f22b-4c7c-bfca-e6a74f12f6cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "from copy import deepcopy\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline.backend_inline\n",
    "import pytorch_lightning as pl\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import STL10\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "plt.set_cmap(\"cividis\")\n",
    "%matplotlib inline\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats(\"svg\", \"pdf\")  # For export\n",
    "matplotlib.rcParams[\"lines.linewidth\"] = 2.0\n",
    "sns.set()\n",
    "\n",
    "# Import tensorboard\n",
    "# %load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4nrL0bJt7UZv",
    "outputId": "40e4309f-8f76-48c1-ba6d-392a353da30a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz to data/stl10_binary.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2640397119/2640397119 [00:50<00:00, 52199124.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/stl10_binary.tar.gz to data/\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "## Data Preparation\n",
    "\n",
    "# Path configurations\n",
    "DATASET_PATH = \"data/\"\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "\n",
    "# Data augmentations for SimCLR\n",
    "contrast_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomResizedCrop(size=96),\n",
    "    transforms.RandomApply([\n",
    "        transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.1)\n",
    "    ], p=0.8),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    transforms.GaussianBlur(kernel_size=9),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Datasets for contrastive learning\n",
    "unlabeled_data = STL10(\n",
    "    root=DATASET_PATH,\n",
    "    split=\"unlabeled\",\n",
    "    download=True,\n",
    "    transform=contrast_transforms\n",
    ")\n",
    "train_data_contrast = STL10(\n",
    "    root=DATASET_PATH,\n",
    "    split=\"train\",\n",
    "    download=True,\n",
    "    transform=contrast_transforms\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "efngwUkA7Uce"
   },
   "outputs": [],
   "source": [
    "## SimCLR model definition\n",
    "\n",
    "class SimCLR(pl.LightningModule):\n",
    "    def __init__(self, hidden_dim=128, num_classes=10, lr=1e-3, temperature=0.07, weight_decay=1e-4, max_epochs=100):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # INTERNAL NOTES\n",
    "        # 1. In the future, try with other backbones (could be Resnet50, could be some EfficientNet)\n",
    "        # 2. Since SimCLR learns representations directly from the data, I'm not using the pre-trained weights by now\n",
    "        # to avoid the bias learned from ImageNet-like datasets. However, this should also be tested.\n",
    "        # Tip: for larger datasets, pretrained=False should work better (because of what I've just exposed)\n",
    "        # while for small datasets, the pretrained weights might provide a performance boost\n",
    "        # Define ResNet backbone\n",
    "        self.convnet = torchvision.models.resnet18(pretrained=False)\n",
    "        self.convnet.fc = nn.Sequential(\n",
    "            nn.Linear(self.convnet.fc.in_features, 4 * hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4 * hidden_dim, hidden_dim)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=self.hparams.lr, weight_decay=self.hparams.weight_decay)\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=self.hparams.max_epochs, eta_min=self.hparams.lr / 50)\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def forward(self, batch, classify=False):\n",
    "        if classify:\n",
    "            imgs = batch\n",
    "            feats = self.convnet(imgs)\n",
    "            return self.classifier(feats)\n",
    "        else:\n",
    "            imgs = batch[0]\n",
    "            # labels = batch[1]\n",
    "            # imgs = torch.cat(imgs, dim=0)\n",
    "            feats = self.convnet(imgs)\n",
    "            cos_sim = F.cosine_similarity(feats[:, None, :], feats[None, :, :], dim=-1)\n",
    "            self_mask = torch.eye(cos_sim.shape[0], device=cos_sim.device, dtype=torch.bool)\n",
    "            cos_sim.masked_fill_(self_mask, -9e15)\n",
    "            pos_mask = self_mask.roll(shifts=cos_sim.shape[0] // 2, dims=0)\n",
    "            cos_sim = cos_sim / self.hparams.temperature\n",
    "            nll = -cos_sim[pos_mask] + torch.logsumexp(cos_sim, dim=-1)\n",
    "            return nll.mean()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self.forward(batch)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434,
     "referenced_widgets": [
      "b4e7813250164218a80bc58ce668d907",
      "0263a5d1d453429a88b839937d2c6889",
      "8457088f9ab9472f97940cd4132a4425",
      "5179e39b424a49119adca3f0792e327f",
      "94a85227b4924db9a9ea7b07f8dc1a98",
      "2031eb6a842e42748b01aa3f35a29857",
      "e6bb968244ef4632a5e21dd168a92771",
      "92e4b7cf9b2a4a688c6ccfe3c3429075",
      "62f81c945bca48b79e1bdbaa3caf0cc4",
      "865cbbd5de8b402b9eca2ae3501ded57",
      "a7eb1c2da6bb46d3b641b59fb4ef4f53"
     ]
    },
    "id": "HrJVtnDv7Ue-",
    "outputId": "82b11bb7-130e-4646-caa3-1d9b9ccd4347"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name       | Type   | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | convnet    | ResNet | 11.5 M | train\n",
      "1 | classifier | Linear | 1.3 K  | train\n",
      "----------------------------------------------\n",
      "11.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.5 M    Total params\n",
      "46.024    Total estimated model params size (MB)\n",
      "72        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e7813250164218a80bc58ce668d907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "## Train SimCLR Model\n",
    "\n",
    "def train_simclr(batch_size=256, max_epochs=100, **kwargs):\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=\"gpu\",\n",
    "        devices=1,\n",
    "        callbacks=[\n",
    "            ModelCheckpoint(save_weights_only=True, monitor=\"train_loss\", mode=\"min\"),\n",
    "            LearningRateMonitor(logging_interval=\"epoch\"),\n",
    "        ]\n",
    "    )\n",
    "    train_loader = torch.utils.data.DataLoader(unlabeled_data, batch_size=batch_size, shuffle=True, num_workers=NUM_WORKERS)\n",
    "    model = SimCLR(num_classes=10, max_epochs=max_epochs, **kwargs)\n",
    "    trainer.fit(model, train_loader)\n",
    "    return model\n",
    "\n",
    "# Train the SimCLR model\n",
    "simclr_model = train_simclr(hidden_dim=128, lr=1e-3, temperature=0.07, weight_decay=1e-4, max_epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "KE0lbR907Uhs"
   },
   "outputs": [],
   "source": [
    "## Save the model\n",
    "\n",
    "torch.save(simclr_model.state_dict(), \"simclr_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "9gpbqr057Ush"
   },
   "outputs": [],
   "source": [
    "## Define MLP Classifier\n",
    "\n",
    "class MLPClassifier(pl.LightningModule):\n",
    "    def __init__(self, feature_dim, num_classes=10, hidden_dim=256, lr=1e-3, weight_decay=1e-4, max_epochs=100):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Define the MLP architecture\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(feature_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=self.hparams.lr, weight_decay=self.hparams.weight_decay)\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=self.hparams.max_epochs, eta_min=self.hparams.lr / 50)\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def _calculate_loss(self, batch, mode=\"train\"):\n",
    "        feats, labels = batch\n",
    "        preds = self.model(feats)\n",
    "        loss = F.cross_entropy(preds, labels)\n",
    "        acc = (preds.argmax(dim=-1) == labels).float().mean()\n",
    "\n",
    "        # Log loss and accuracy\n",
    "        self.log(f\"{mode}_loss\", loss, prog_bar=True)\n",
    "        self.log(f\"{mode}_acc\", acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._calculate_loss(batch, mode=\"train\")\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self._calculate_loss(batch, mode=\"val\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        self._calculate_loss(batch, mode=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "id": "4tPYqz6j7UvO",
    "outputId": "2356820a-f7e4-4e43-f10a-4727cc1eaa22"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data_contrast' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5348d2b5be74>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mmlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_mlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_feats_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data_contrast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_feats_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data_contrast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data_contrast' is not defined"
     ]
    }
   ],
   "source": [
    "## Train the MLP Classifier\n",
    "\n",
    "def train_mlp(batch_size, train_feats_data, test_feats_data, max_epochs=100, **kwargs):\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=\"gpu\",\n",
    "        devices=1,\n",
    "        callbacks=[\n",
    "            pl.callbacks.ModelCheckpoint(save_weights_only=True, monitor=\"val_acc\", mode=\"max\"),\n",
    "            pl.callbacks.LearningRateMonitor(\"epoch\"),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Data loaders\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_feats_data, batch_size=batch_size, shuffle=True, drop_last=False, num_workers=4\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_feats_data, batch_size=batch_size, shuffle=False, drop_last=False, num_workers=4\n",
    "    )\n",
    "\n",
    "    # Train the MLP\n",
    "    model = MLPClassifier(num_classes=10, max_epochs=max_epochs, feature_dim=96, **kwargs)\n",
    "    trainer.fit(model, train_loader, test_loader)\n",
    "\n",
    "    # Test the model\n",
    "    test_result = trainer.test(model, test_loader, verbose=False)\n",
    "    print(f\"Test accuracy: {test_result[0]['test_acc'] * 100:.2f}%\")\n",
    "\n",
    "    return model\n",
    "\n",
    "# mlp_model = train_mlp(batch_size=256, train_feats_data=train_data_contrast, test_feats_data=train_data_contrast, max_epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mcNzmQHd7Uxr"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from captum.attr import IntegratedGradients\n",
    "\n",
    "def run_explainability(model):\n",
    "    model.eval()\n",
    "\n",
    "    # Select the target class for which you want to explain predictions\n",
    "    dataset = train_data_contrast\n",
    "\n",
    "    # Get a single example from the dataset\n",
    "    input_tensor, label = dataset[0]\n",
    "    input_tensor = input_tensor.unsqueeze(0)\n",
    "\n",
    "    print(f\"Got an example input tensor of shape {input_tensor.shape}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor, classify=True)\n",
    "        target_class = logits.argmax(dim=-1).item()\n",
    "\n",
    "    print(f\"Predicted class: {target_class}\")\n",
    "\n",
    "    def forward_fn(inputs):\n",
    "        if inputs.dim() == 3:\n",
    "            inputs = inputs.unsqueeze(0)\n",
    "        return model(inputs, classify=True)\n",
    "\n",
    "    ig = IntegratedGradients(forward_fn)\n",
    "    attributions, delta = ig.attribute(\n",
    "        input_tensor, target=target_class, return_convergence_delta=True\n",
    "    )\n",
    "    attributions_np = attributions[0].cpu().detach().numpy()\n",
    "\n",
    "    attributions_np = (attributions_np - attributions_np.min()) / (attributions_np.max() - attributions_np.min())\n",
    "\n",
    "    print(\"Preparing image with attributions\")\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    ax[0].imshow(input_tensor[0].cpu().permute(1, 2, 0))\n",
    "    ax[0].set_title('Original Image')\n",
    "    ax[1].imshow(attributions_np.transpose(1, 2, 0))\n",
    "    ax[1].set_title('Attributions')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "33nF2jocFtko"
   },
   "outputs": [],
   "source": [
    "run_explainability(model=simclr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2tA3HwGpQ3cE"
   },
   "outputs": [],
   "source": [
    "# run_explainability(model=mlp_model)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ml-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0263a5d1d453429a88b839937d2c6889": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2031eb6a842e42748b01aa3f35a29857",
      "placeholder": "​",
      "style": "IPY_MODEL_e6bb968244ef4632a5e21dd168a92771",
      "value": "Epoch 9: 100%"
     }
    },
    "2031eb6a842e42748b01aa3f35a29857": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5179e39b424a49119adca3f0792e327f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_865cbbd5de8b402b9eca2ae3501ded57",
      "placeholder": "​",
      "style": "IPY_MODEL_a7eb1c2da6bb46d3b641b59fb4ef4f53",
      "value": " 391/391 [05:36&lt;00:00,  1.16it/s, v_num=0]"
     }
    },
    "62f81c945bca48b79e1bdbaa3caf0cc4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8457088f9ab9472f97940cd4132a4425": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_92e4b7cf9b2a4a688c6ccfe3c3429075",
      "max": 391,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_62f81c945bca48b79e1bdbaa3caf0cc4",
      "value": 391
     }
    },
    "865cbbd5de8b402b9eca2ae3501ded57": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "92e4b7cf9b2a4a688c6ccfe3c3429075": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "94a85227b4924db9a9ea7b07f8dc1a98": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "a7eb1c2da6bb46d3b641b59fb4ef4f53": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b4e7813250164218a80bc58ce668d907": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0263a5d1d453429a88b839937d2c6889",
       "IPY_MODEL_8457088f9ab9472f97940cd4132a4425",
       "IPY_MODEL_5179e39b424a49119adca3f0792e327f"
      ],
      "layout": "IPY_MODEL_94a85227b4924db9a9ea7b07f8dc1a98"
     }
    },
    "e6bb968244ef4632a5e21dd168a92771": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
