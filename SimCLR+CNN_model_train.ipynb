{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nJ2X_5sG7Qox",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2324396-4098-4757-986b-20c420bec267"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics<1.5,>=1.0\n",
            "  Downloading torchmetrics-1.4.3-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Requirement already satisfied: numpy<3.0 in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Collecting torch<2.5,>=1.8.1\n",
            "  Downloading torch-2.4.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting pytorch-lightning<2.5,>=2.0\n",
            "  Downloading pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics<1.5,>=1.0) (24.2)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics<1.5,>=1.0)\n",
            "  Downloading lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn) (2.2.2)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.20.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading torchvision-0.20.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading torchvision-0.19.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<2.5,>=1.8.1) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch<2.5,>=1.8.1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<2.5,>=1.8.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<2.5,>=1.8.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<2.5,>=1.8.1) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<2.5,>=1.8.1) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<2.5,>=1.8.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<2.5,>=1.8.1)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<2.5,>=1.8.1)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<2.5,>=1.8.1)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch<2.5,>=1.8.1)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch<2.5,>=1.8.1)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch<2.5,>=1.8.1)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch<2.5,>=1.8.1)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch<2.5,>=1.8.1)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch<2.5,>=1.8.1)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch<2.5,>=1.8.1)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.0.0 (from torch<2.5,>=1.8.1)\n",
            "  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<2.5,>=1.8.1) (12.6.85)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.68.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (4.25.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning<2.5,>=2.0) (4.66.6)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning<2.5,>=2.0) (6.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning<2.5,>=2.0) (3.11.9)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<2.5,>=1.8.1) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5,>=2.0) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5,>=2.0) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5,>=2.0) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5,>=2.0) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5,>=2.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5,>=2.0) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5,>=2.0) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5,>=2.0) (1.18.3)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5,>=2.0) (3.10)\n",
            "Downloading torchmetrics-1.4.3-py3-none-any.whl (869 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m869.5/869.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.19.1-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.4.1-cp310-cp310-manylinux1_x86_64.whl (797.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.1/797.1 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchmetrics, pytorch-lightning\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.6.0.74\n",
            "    Uninstalling nvidia-cudnn-cu12-9.6.0.74:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.6.0.74\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu121\n",
            "    Uninstalling torch-2.5.1+cu121:\n",
            "      Successfully uninstalled torch-2.5.1+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.20.1+cu121\n",
            "    Uninstalling torchvision-0.20.1+cu121:\n",
            "      Successfully uninstalled torchvision-0.20.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.4.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lightning-utilities-0.11.9 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 pytorch-lightning-2.4.0 torch-2.4.1 torchmetrics-1.4.3 torchvision-0.19.1 triton-3.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install \"torchmetrics >=1.0,<1.5\" \"seaborn\" \"numpy <3.0\" \"torchvision\" \"tensorboard\" \"torch >=1.8.1,<2.5\" \"pytorch-lightning >=2.0,<2.5\" \"matplotlib\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kp_z2uj77UXD",
        "outputId": "fa1d5148-f22b-4c7c-bfca-e6a74f12f6cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os\n",
        "import urllib.request\n",
        "from copy import deepcopy\n",
        "from urllib.error import HTTPError\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib_inline.backend_inline\n",
        "import pytorch_lightning as pl\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import STL10\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "plt.set_cmap(\"cividis\")\n",
        "%matplotlib inline\n",
        "matplotlib_inline.backend_inline.set_matplotlib_formats(\"svg\", \"pdf\")  # For export\n",
        "matplotlib.rcParams[\"lines.linewidth\"] = 2.0\n",
        "sns.set()\n",
        "\n",
        "# Import tensorboard\n",
        "# %load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4nrL0bJt7UZv",
        "outputId": "40e4309f-8f76-48c1-ba6d-392a353da30a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz to data/stl10_binary.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2640397119/2640397119 [00:50<00:00, 52199124.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/stl10_binary.tar.gz to data/\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "## Data Preparation\n",
        "\n",
        "# Path configurations\n",
        "DATASET_PATH = \"data/\"\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "\n",
        "# Data augmentations for SimCLR\n",
        "contrast_transforms = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomResizedCrop(size=96),\n",
        "    transforms.RandomApply([\n",
        "        transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.1)\n",
        "    ], p=0.8),\n",
        "    transforms.RandomGrayscale(p=0.2),\n",
        "    transforms.GaussianBlur(kernel_size=9),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Datasets for contrastive learning\n",
        "unlabeled_data = STL10(\n",
        "    root=DATASET_PATH,\n",
        "    split=\"unlabeled\",\n",
        "    download=True,\n",
        "    transform=contrast_transforms\n",
        ")\n",
        "train_data_contrast = STL10(\n",
        "    root=DATASET_PATH,\n",
        "    split=\"train\",\n",
        "    download=True,\n",
        "    transform=contrast_transforms\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "efngwUkA7Uce"
      },
      "outputs": [],
      "source": [
        "## SimCLR model definition\n",
        "\n",
        "class SimCLR(pl.LightningModule):\n",
        "    def __init__(self, hidden_dim=128, num_classes=10, lr=1e-3, temperature=0.07, weight_decay=1e-4, max_epochs=100):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        # INTERNAL NOTES\n",
        "        # 1. In the future, try with other backbones (could be Resnet50, could be some EfficientNet)\n",
        "        # 2. Since SimCLR learns representations directly from the data, I'm not using the pre-trained weights by now\n",
        "        # to avoid the bias learned from ImageNet-like datasets. However, this should also be tested.\n",
        "        # Tip: for larger datasets, pretrained=False should work better (because of what I've just exposed)\n",
        "        # while for small datasets, the pretrained weights might provide a performance boost\n",
        "        # Define ResNet backbone\n",
        "        self.convnet = torchvision.models.resnet18(pretrained=False)\n",
        "        self.convnet.fc = nn.Sequential(\n",
        "            nn.Linear(self.convnet.fc.in_features, 4 * hidden_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4 * hidden_dim, hidden_dim)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = optim.AdamW(self.parameters(), lr=self.hparams.lr, weight_decay=self.hparams.weight_decay)\n",
        "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=self.hparams.max_epochs, eta_min=self.hparams.lr / 50)\n",
        "        return [optimizer], [scheduler]\n",
        "\n",
        "    def forward(self, batch, classify=False):\n",
        "        if classify:\n",
        "            imgs = batch\n",
        "            feats = self.convnet(imgs)\n",
        "            return self.classifier(feats)\n",
        "        else:\n",
        "            imgs = batch[0]\n",
        "            # labels = batch[1]\n",
        "            # imgs = torch.cat(imgs, dim=0)\n",
        "            feats = self.convnet(imgs)\n",
        "            cos_sim = F.cosine_similarity(feats[:, None, :], feats[None, :, :], dim=-1)\n",
        "            self_mask = torch.eye(cos_sim.shape[0], device=cos_sim.device, dtype=torch.bool)\n",
        "            cos_sim.masked_fill_(self_mask, -9e15)\n",
        "            pos_mask = self_mask.roll(shifts=cos_sim.shape[0] // 2, dims=0)\n",
        "            cos_sim = cos_sim / self.hparams.temperature\n",
        "            nll = -cos_sim[pos_mask] + torch.logsumexp(cos_sim, dim=-1)\n",
        "            return nll.mean()\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        loss = self.forward(batch)\n",
        "        self.log(\"train_loss\", loss)\n",
        "        return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HrJVtnDv7Ue-",
        "outputId": "82b11bb7-130e-4646-caa3-1d9b9ccd4347",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434,
          "referenced_widgets": [
            "b4e7813250164218a80bc58ce668d907",
            "0263a5d1d453429a88b839937d2c6889",
            "8457088f9ab9472f97940cd4132a4425",
            "5179e39b424a49119adca3f0792e327f",
            "94a85227b4924db9a9ea7b07f8dc1a98",
            "2031eb6a842e42748b01aa3f35a29857",
            "e6bb968244ef4632a5e21dd168a92771",
            "92e4b7cf9b2a4a688c6ccfe3c3429075",
            "62f81c945bca48b79e1bdbaa3caf0cc4",
            "865cbbd5de8b402b9eca2ae3501ded57",
            "a7eb1c2da6bb46d3b641b59fb4ef4f53"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name       | Type   | Params | Mode \n",
            "----------------------------------------------\n",
            "0 | convnet    | ResNet | 11.5 M | train\n",
            "1 | classifier | Linear | 1.3 K  | train\n",
            "----------------------------------------------\n",
            "11.5 M    Trainable params\n",
            "0         Non-trainable params\n",
            "11.5 M    Total params\n",
            "46.024    Total estimated model params size (MB)\n",
            "72        Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b4e7813250164218a80bc58ce668d907"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=10` reached.\n"
          ]
        }
      ],
      "source": [
        "## Train SimCLR Model\n",
        "\n",
        "def train_simclr(batch_size=256, max_epochs=100, **kwargs):\n",
        "    trainer = pl.Trainer(\n",
        "        max_epochs=max_epochs,\n",
        "        accelerator=\"gpu\",\n",
        "        devices=1,\n",
        "        callbacks=[\n",
        "            ModelCheckpoint(save_weights_only=True, monitor=\"train_loss\", mode=\"min\"),\n",
        "            LearningRateMonitor(logging_interval=\"epoch\"),\n",
        "        ]\n",
        "    )\n",
        "    train_loader = torch.utils.data.DataLoader(unlabeled_data, batch_size=batch_size, shuffle=True, num_workers=NUM_WORKERS)\n",
        "    model = SimCLR(num_classes=10, max_epochs=max_epochs, **kwargs)\n",
        "    trainer.fit(model, train_loader)\n",
        "    return model\n",
        "\n",
        "# Train the SimCLR model\n",
        "simclr_model = train_simclr(hidden_dim=128, lr=1e-3, temperature=0.07, weight_decay=1e-4, max_epochs=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KE0lbR907Uhs"
      },
      "outputs": [],
      "source": [
        "## Save the model\n",
        "\n",
        "torch.save(simclr_model.state_dict(), \"simclr_model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9gpbqr057Ush"
      },
      "outputs": [],
      "source": [
        "## Define MLP Classifier\n",
        "\n",
        "class MLPClassifier(pl.LightningModule):\n",
        "    def __init__(self, feature_dim, num_classes=10, hidden_dim=256, lr=1e-3, weight_decay=1e-4, max_epochs=100):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        # Define the MLP architecture\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(feature_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(hidden_dim, num_classes)\n",
        "        )\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = optim.AdamW(self.parameters(), lr=self.hparams.lr, weight_decay=self.hparams.weight_decay)\n",
        "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=self.hparams.max_epochs, eta_min=self.hparams.lr / 50)\n",
        "        return [optimizer], [scheduler]\n",
        "\n",
        "    def _calculate_loss(self, batch, mode=\"train\"):\n",
        "        feats, labels = batch\n",
        "        preds = self.model(feats)\n",
        "        loss = F.cross_entropy(preds, labels)\n",
        "        acc = (preds.argmax(dim=-1) == labels).float().mean()\n",
        "\n",
        "        # Log loss and accuracy\n",
        "        self.log(f\"{mode}_loss\", loss, prog_bar=True)\n",
        "        self.log(f\"{mode}_acc\", acc, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        return self._calculate_loss(batch, mode=\"train\")\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        self._calculate_loss(batch, mode=\"val\")\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        self._calculate_loss(batch, mode=\"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4tPYqz6j7UvO",
        "outputId": "2356820a-f7e4-4e43-f10a-4727cc1eaa22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_data_contrast' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5348d2b5be74>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mmlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_mlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_feats_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data_contrast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_feats_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data_contrast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_data_contrast' is not defined"
          ]
        }
      ],
      "source": [
        "## Train the MLP Classifier\n",
        "\n",
        "def train_mlp(batch_size, train_feats_data, test_feats_data, max_epochs=100, **kwargs):\n",
        "    trainer = pl.Trainer(\n",
        "        max_epochs=max_epochs,\n",
        "        accelerator=\"gpu\",\n",
        "        devices=1,\n",
        "        callbacks=[\n",
        "            pl.callbacks.ModelCheckpoint(save_weights_only=True, monitor=\"val_acc\", mode=\"max\"),\n",
        "            pl.callbacks.LearningRateMonitor(\"epoch\"),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    # Data loaders\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_feats_data, batch_size=batch_size, shuffle=True, drop_last=False, num_workers=4\n",
        "    )\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        test_feats_data, batch_size=batch_size, shuffle=False, drop_last=False, num_workers=4\n",
        "    )\n",
        "\n",
        "    # Train the MLP\n",
        "    model = MLPClassifier(num_classes=10, max_epochs=max_epochs, feature_dim=96, **kwargs)\n",
        "    trainer.fit(model, train_loader, test_loader)\n",
        "\n",
        "    # Test the model\n",
        "    test_result = trainer.test(model, test_loader, verbose=False)\n",
        "    print(f\"Test accuracy: {test_result[0]['test_acc'] * 100:.2f}%\")\n",
        "\n",
        "    return model\n",
        "\n",
        "# mlp_model = train_mlp(batch_size=256, train_feats_data=train_data_contrast, test_feats_data=train_data_contrast, max_epochs=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install captum"
      ],
      "metadata": {
        "id": "4dgOu4lUdjgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcNzmQHd7Uxr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from captum.attr import IntegratedGradients\n",
        "\n",
        "def run_explainability(model):\n",
        "    model.eval()\n",
        "\n",
        "    # Select the target class for which you want to explain predictions\n",
        "    dataset = train_data_contrast\n",
        "\n",
        "    # Get a single example from the dataset\n",
        "    input_tensor, label = dataset[0]\n",
        "    input_tensor = input_tensor.unsqueeze(0)\n",
        "\n",
        "    print(f\"Got an example input tensor of shape {input_tensor.shape}\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_tensor, classify=True)\n",
        "        target_class = logits.argmax(dim=-1).item()\n",
        "\n",
        "    print(f\"Predicted class: {target_class}\")\n",
        "\n",
        "    def forward_fn(inputs):\n",
        "        if inputs.dim() == 3:\n",
        "            inputs = inputs.unsqueeze(0)\n",
        "        return model(inputs, classify=True)\n",
        "\n",
        "    ig = IntegratedGradients(forward_fn)\n",
        "    attributions, delta = ig.attribute(\n",
        "        input_tensor, target=target_class, return_convergence_delta=True\n",
        "    )\n",
        "    attributions_np = attributions[0].cpu().detach().numpy()\n",
        "\n",
        "    attributions_np = (attributions_np - attributions_np.min()) / (attributions_np.max() - attributions_np.min())\n",
        "\n",
        "    print(\"Preparing image with attributions\")\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
        "    ax[0].imshow(input_tensor[0].cpu().permute(1, 2, 0))\n",
        "    ax[0].set_title('Original Image')\n",
        "    ax[1].imshow(attributions_np.transpose(1, 2, 0))\n",
        "    ax[1].set_title('Attributions')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_explainability(model=simclr_model)"
      ],
      "metadata": {
        "id": "33nF2jocFtko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run_explainability(model=mlp_model)"
      ],
      "metadata": {
        "id": "2tA3HwGpQ3cE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b4e7813250164218a80bc58ce668d907": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0263a5d1d453429a88b839937d2c6889",
              "IPY_MODEL_8457088f9ab9472f97940cd4132a4425",
              "IPY_MODEL_5179e39b424a49119adca3f0792e327f"
            ],
            "layout": "IPY_MODEL_94a85227b4924db9a9ea7b07f8dc1a98"
          }
        },
        "0263a5d1d453429a88b839937d2c6889": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2031eb6a842e42748b01aa3f35a29857",
            "placeholder": "​",
            "style": "IPY_MODEL_e6bb968244ef4632a5e21dd168a92771",
            "value": "Epoch 9: 100%"
          }
        },
        "8457088f9ab9472f97940cd4132a4425": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92e4b7cf9b2a4a688c6ccfe3c3429075",
            "max": 391,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_62f81c945bca48b79e1bdbaa3caf0cc4",
            "value": 391
          }
        },
        "5179e39b424a49119adca3f0792e327f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_865cbbd5de8b402b9eca2ae3501ded57",
            "placeholder": "​",
            "style": "IPY_MODEL_a7eb1c2da6bb46d3b641b59fb4ef4f53",
            "value": " 391/391 [05:36&lt;00:00,  1.16it/s, v_num=0]"
          }
        },
        "94a85227b4924db9a9ea7b07f8dc1a98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "2031eb6a842e42748b01aa3f35a29857": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6bb968244ef4632a5e21dd168a92771": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92e4b7cf9b2a4a688c6ccfe3c3429075": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62f81c945bca48b79e1bdbaa3caf0cc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "865cbbd5de8b402b9eca2ae3501ded57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7eb1c2da6bb46d3b641b59fb4ef4f53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}